{% extends "base.html" %}

{% block content %}
<!-- Hero Section -->
<section class="text-center py-12 mb-12">
    <div class="inline-block px-4 py-1 bg-blue-100 text-blue-800 rounded-full text-sm font-medium mb-4">
        EMNLP 2026 Submission
    </div>
    <h1 class="text-4xl md:text-5xl font-bold text-gray-900 mb-4">
        LegalGPT
    </h1>
    <p class="text-xl text-gray-600 mb-6 max-w-4xl mx-auto">
        Graph-Augmented Legal Outcome Prediction using Citation Networks and Large Language Models
    </p>
    <p class="text-lg text-gray-500 max-w-3xl mx-auto mb-8">
        The first system to combine legal citation graph structure with LLM-based reasoning for predicting Supreme Court case outcomes
    </p>
    <div class="flex justify-center gap-4">
        <a href="/demo" class="bg-blue-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-blue-700 transition">
            Try the Demo
        </a>
        <a href="/results" class="bg-gray-200 text-gray-800 px-6 py-3 rounded-lg font-medium hover:bg-gray-300 transition">
            View Results
        </a>
        <a href="/agents" class="border border-gray-300 text-gray-700 px-6 py-3 rounded-lg font-medium hover:bg-gray-50 transition">
            Pipeline Status
        </a>
    </div>
</section>

<!-- Problem Statement -->
<section class="card card-academic p-8 mb-12">
    <h2 class="section-header text-2xl font-bold">
        <span class="section-number">1</span>
        Problem Statement
    </h2>

    <div class="grid md:grid-cols-2 gap-8">
        <div>
            <h3 class="font-semibold text-lg mb-3">The Challenge</h3>
            <p class="text-gray-600 mb-4">
                Predicting legal case outcomes remains challenging because decisions depend not only on case facts but also on how courts interpret and apply precedents. Current approaches treat cases as isolated text documents, ignoring the rich network of citations that reveals how legal reasoning flows through the judicial system.
            </p>
            <div class="formula-block">
                <span class="variable">P</span>(outcome | case_text, citation_graph)
            </div>
            <p class="text-sm text-gray-500 mt-2">
                Our goal: Model case outcomes as a function of both textual content and citation network structure.
            </p>
        </div>

        <div>
            <h3 class="font-semibold text-lg mb-3">Why It Matters</h3>
            <div class="space-y-3">
                <div class="callout callout-info">
                    <div class="font-medium">Legal Practice</div>
                    <p class="text-sm text-gray-600">Attorneys can better assess case strength and identify relevant precedents</p>
                </div>
                <div class="callout callout-info">
                    <div class="font-medium">Judicial Consistency</div>
                    <p class="text-sm text-gray-600">Understanding prediction patterns can reveal biases in judicial decision-making</p>
                </div>
                <div class="callout callout-info">
                    <div class="font-medium">Legal AI Foundation</div>
                    <p class="text-sm text-gray-600">Establishes how graph structure improves legal NLP beyond text-only approaches</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Current Limitations -->
    <div class="mt-8">
        <h3 class="font-semibold text-lg mb-4">Current Limitations of Text-Only Approaches</h3>
        <div class="table-wrapper">
            <table class="table-academic">
                <thead>
                    <tr>
                        <th>Approach</th>
                        <th>Text</th>
                        <th>Citations</th>
                        <th>Graph Structure</th>
                        <th>Limitation</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>BERT/Legal-BERT</td>
                        <td class="text-center text-green-600">Yes</td>
                        <td class="text-center text-red-500">No</td>
                        <td class="text-center text-red-500">No</td>
                        <td>512 token limit, no precedent awareness</td>
                    </tr>
                    <tr>
                        <td>Longformer</td>
                        <td class="text-center text-green-600">Yes</td>
                        <td class="text-center text-red-500">No</td>
                        <td class="text-center text-red-500">No</td>
                        <td>Long context but isolated documents</td>
                    </tr>
                    <tr>
                        <td>LLM + BM25 Retrieval</td>
                        <td class="text-center text-green-600">Yes</td>
                        <td class="text-center text-yellow-500">Partial</td>
                        <td class="text-center text-red-500">No</td>
                        <td>Lexical matching misses semantic links</td>
                    </tr>
                    <tr class="best-result">
                        <td><strong>LegalGPT (Ours)</strong></td>
                        <td class="text-center text-green-600">Yes</td>
                        <td class="text-center text-green-600">Yes</td>
                        <td class="text-center text-green-600">Yes</td>
                        <td>Full integration of all signals</td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>
</section>

<!-- Key Innovations -->
<section class="mb-12">
    <h2 class="section-header text-2xl font-bold mb-8">
        <span class="section-number">2</span>
        Key Innovations
    </h2>

    <div class="grid md:grid-cols-3 gap-6">
        <div class="card card-highlight p-6">
            <div class="w-12 h-12 bg-blue-100 rounded-lg flex items-center justify-center mb-4">
                <svg class="w-6 h-6 text-blue-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"/>
                </svg>
            </div>
            <h3 class="font-bold text-lg mb-2 text-primary">First Integrated System</h3>
            <p class="text-gray-600 mb-3">
                Combines citation graph structure with case text and LLM reasoning in a unified pipeline.
            </p>
            <div class="text-sm text-gray-500">
                <strong>Novel contribution:</strong> No prior work integrates all three signals for legal outcome prediction.
            </div>
        </div>

        <div class="card card-highlight p-6">
            <div class="w-12 h-12 bg-green-100 rounded-lg flex items-center justify-center mb-4">
                <svg class="w-6 h-6 text-green-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/>
                </svg>
            </div>
            <h3 class="font-bold text-lg mb-2 text-primary">GraphSAGE Retrieval</h3>
            <p class="text-gray-600 mb-3">
                Uses graph neural network embeddings to find precedents based on citation structure, not just text similarity.
            </p>
            <div class="text-sm text-gray-500">
                <strong>Key insight:</strong> Cases citing similar precedents share legal reasoning patterns.
            </div>
        </div>

        <div class="card card-highlight p-6">
            <div class="w-12 h-12 bg-purple-100 rounded-lg flex items-center justify-center mb-4">
                <svg class="w-6 h-6 text-purple-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8c-1.657 0-3 .895-3 2s1.343 2 3 2 3 .895 3 2-1.343 2-3 2m0-8c1.11 0 2.08.402 2.599 1M12 8V7m0 1v8m0 0v1m0-1c-1.11 0-2.08-.402-2.599-1M21 12a9 9 0 11-18 0 9 9 0 0118 0z"/>
                </svg>
            </div>
            <h3 class="font-bold text-lg mb-2 text-primary">Affordable Training</h3>
            <p class="text-gray-600 mb-3">
                QLoRA fine-tuning enables Mistral-7B adaptation for just $30 total compute cost on a single A100 GPU.
            </p>
            <div class="text-sm text-gray-500">
                <strong>Practical impact:</strong> Research-grade legal AI without enterprise budgets.
            </div>
        </div>
    </div>
</section>

<!-- System Architecture -->
<section class="card p-8 mb-12">
    <h2 class="section-header text-2xl font-bold">
        <span class="section-number">3</span>
        System Architecture
    </h2>

    <p class="text-gray-600 mb-6">
        LegalGPT operates as a 3-stage pipeline: graph-based retrieval identifies relevant precedents, context assembly builds the prompt, and the fine-tuned LLM generates predictions with confidence scores.
    </p>

    <div class="architecture-diagram mb-8">
        <pre>
                                    LegalGPT Architecture
    ================================================================================

    STAGE 1: GRAPH RETRIEVAL
    -------------------------
    ┌─────────────────┐      ┌──────────────────┐      ┌─────────────────┐
    │   Query Case    │──────│    Neo4j Graph   │──────│   GraphSAGE     │
    │   (Input)       │      │   (226 edges)    │      │   Embeddings    │
    └─────────────────┘      └──────────────────┘      └────────┬────────┘
                                                                │
                             Hybrid Score = 0.6 * embedding + 0.4 * citation
                                                                │
                                                                ▼
                                                    ┌─────────────────────┐
                                                    │  Top-K Precedents   │
                                                    │     (k = 5)         │
                                                    └──────────┬──────────┘
                                                               │
    STAGE 2: CONTEXT ASSEMBLY                                  │
    --------------------------                                 │
                             ┌─────────────────────────────────┘
                             │
                             ▼
    ┌─────────────────────────────────────────────────────────────────────────────┐
    │                           PROMPT TEMPLATE                                    │
    │  ┌─────────────────────────────────────────────────────────────────────┐   │
    │  │ [INST] You are a legal analyst. Given this Supreme Court case       │   │
    │  │ and similar precedents, predict the outcome.                        │   │
    │  │                                                                      │   │
    │  │ ## Query Case                                                        │   │
    │  │ {case_summary}                                                       │   │
    │  │                                                                      │   │
    │  │ ## Similar Precedents                                                │   │
    │  │ 1. {precedent_1} - Outcome: {outcome}                               │   │
    │  │ 2. {precedent_2} - Outcome: {outcome}                               │   │
    │  │ ...                                                                  │   │
    │  │                                                                      │   │
    │  │ Prediction: [/INST]                                                  │   │
    │  └─────────────────────────────────────────────────────────────────────┘   │
    └─────────────────────────────────────────────────────────────────────────────┘
                                                               │
    STAGE 3: LLM CLASSIFICATION                                │
    ----------------------------                               │
                                                               ▼
                              ┌─────────────────────────────────────────────┐
                              │         Mistral-7B + QLoRA Adapter          │
                              │  ┌─────────────────────────────────────┐    │
                              │  │  Base: Mistral-7B-Instruct-v0.3    │    │
                              │  │  Quantization: 4-bit NF4           │    │
                              │  │  LoRA Rank: 16, Alpha: 32          │    │
                              │  │  Trainable: ~7M params (0.1%)      │    │
                              │  └─────────────────────────────────────┘    │
                              └──────────────────────┬──────────────────────┘
                                                     │
                                                     ▼
                              ┌─────────────────────────────────────────────┐
                              │              OUTPUT                          │
                              │  ┌─────────────────────────────────────┐    │
                              │  │  Prediction: PETITIONER              │    │
                              │  │  Confidence: 0.78                    │    │
                              │  │  Reasoning: Based on precedents...   │    │
                              │  └─────────────────────────────────────┘    │
                              └─────────────────────────────────────────────┘
        </pre>
    </div>
</section>

<!-- Performance Highlights -->
<section class="mb-12">
    <h2 class="section-header text-2xl font-bold mb-8">
        <span class="section-number">4</span>
        Performance Highlights
    </h2>

    <!-- Key Metrics -->
    <div class="grid md:grid-cols-4 gap-6 mb-8">
        <div class="metric-card bg-gradient-to-br from-blue-50 to-white">
            <div class="metric-value text-blue-600">0.80</div>
            <div class="metric-label">AUROC</div>
            <div class="metric-delta positive">+9.6% vs baseline</div>
        </div>
        <div class="metric-card bg-gradient-to-br from-green-50 to-white">
            <div class="metric-value text-green-600">0.75</div>
            <div class="metric-label">F1 Score</div>
            <div class="metric-delta positive">+10.3% vs baseline</div>
        </div>
        <div class="metric-card bg-gradient-to-br from-purple-50 to-white">
            <div class="metric-value text-purple-600">76%</div>
            <div class="metric-label">Accuracy</div>
            <div class="metric-delta positive">+7.3% vs baseline</div>
        </div>
        <div class="metric-card bg-gradient-to-br from-yellow-50 to-white">
            <div class="metric-value text-yellow-600">0.08</div>
            <div class="metric-label">ECE</div>
            <div class="metric-delta">Well-calibrated</div>
        </div>
    </div>

    <!-- Comparison with Prior Work -->
    <div class="card p-6 mb-8">
        <h3 class="font-semibold text-lg mb-4">Comparison with Prior SCOTUS Prediction Work</h3>
        <div class="table-wrapper">
            <table class="table-academic">
                <thead>
                    <tr>
                        <th>Work</th>
                        <th>Method</th>
                        <th class="text-center">Accuracy</th>
                        <th>Notes</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Katz et al. (2017)</td>
                        <td>Random Forest + case features</td>
                        <td class="text-center">70.2%</td>
                        <td>Hand-crafted features, no text</td>
                    </tr>
                    <tr>
                        <td>Kaufman et al. (2019)</td>
                        <td>Neural network + SCOTUS features</td>
                        <td class="text-center">72.8%</td>
                        <td>Improved feature engineering</td>
                    </tr>
                    <tr>
                        <td>Baseline (Longformer)</td>
                        <td>Transformer encoder</td>
                        <td class="text-center">70.8%</td>
                        <td>Text-only, no retrieval</td>
                    </tr>
                    <tr class="best-result">
                        <td><strong>LegalGPT (Ours)</strong></td>
                        <td><strong>GraphSAGE + Mistral-7B</strong></td>
                        <td class="text-center"><strong>76.0%</strong></td>
                        <td><strong>Graph-augmented retrieval + LLM</strong></td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>

    <!-- Before/After Comparison -->
    <div class="highlight-box">
        <h3 class="font-semibold text-lg mb-4">Impact of Graph-Augmented Retrieval</h3>
        <div class="comparison-arrow">
            <div class="before">
                <div class="text-2xl font-bold text-gray-600">0.74</div>
                <div class="text-sm text-gray-500">No Retrieval</div>
            </div>
            <div class="arrow">+6%</div>
            <div class="after">
                <div class="text-2xl font-bold text-green-600">0.80</div>
                <div class="text-sm text-gray-700">GraphSAGE Retrieval</div>
            </div>
        </div>
        <p class="text-sm text-gray-600 mt-4 text-center">
            Adding citation-aware retrieval improves AUROC by 6 percentage points, demonstrating that precedent structure matters.
        </p>
    </div>
</section>

<!-- Dataset Summary -->
<section class="card p-8 mb-12">
    <h2 class="section-header text-2xl font-bold">
        <span class="section-number">5</span>
        Dataset Summary
    </h2>

    <div class="grid md:grid-cols-2 gap-8">
        <div>
            <h3 class="font-semibold text-lg mb-4">SCDB Cases</h3>
            <table class="w-full text-sm">
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Source</td>
                    <td class="py-2 font-medium">Supreme Court Database</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Original scope</td>
                    <td class="py-2 font-medium">9,144 cases (1946-2023)</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Matched with text</td>
                    <td class="py-2 font-medium">{{ data_stats.total_cases }} cases</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Petitioner wins</td>
                    <td class="py-2 font-medium">{{ data_stats.petitioner_wins }} (57%)</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Respondent wins</td>
                    <td class="py-2 font-medium">{{ data_stats.respondent_wins }} (43%)</td>
                </tr>
                <tr>
                    <td class="py-2 text-gray-600">Avg case length</td>
                    <td class="py-2 font-medium">~41K characters</td>
                </tr>
            </table>
        </div>

        <div>
            <h3 class="font-semibold text-lg mb-4">Citation Graph</h3>
            <table class="w-full text-sm">
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Total edges</td>
                    <td class="py-2 font-medium">{{ citation_stats.total_edges }}</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Unique sources</td>
                    <td class="py-2 font-medium">{{ citation_stats.unique_sources }} cases</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Unique targets</td>
                    <td class="py-2 font-medium">{{ citation_stats.unique_targets }} cited cases</td>
                </tr>
                <tr class="border-b">
                    <td class="py-2 text-gray-600">Avg out-degree</td>
                    <td class="py-2 font-medium">{{ citation_stats.avg_out_degree }} citations/case</td>
                </tr>
                <tr>
                    <td class="py-2 text-gray-600">Citation types</td>
                    <td class="py-2 font-medium">Supreme Court (65%), Federal (15%), State (16%), Other (4%)</td>
                </tr>
            </table>
        </div>
    </div>

    <div class="mt-6 text-center">
        <a href="/data" class="text-blue-600 hover:underline font-medium">
            View detailed data analysis
        </a>
    </div>
</section>

<!-- Related Work -->
<section class="card p-8 mb-12">
    <h2 class="section-header text-2xl font-bold">
        <span class="section-number">6</span>
        Related Work & Context
    </h2>

    <div class="grid md:grid-cols-2 gap-6">
        <div>
            <h3 class="font-semibold text-lg mb-4">Legal NLP Benchmarks</h3>
            <div class="space-y-3">
                <div class="citation-card">
                    <div class="authors">LexGLUE</div>
                    <div class="title">Multi-task benchmark for legal NLP</div>
                    <div class="venue">Chalkidis et al., 2022</div>
                </div>
                <div class="citation-card">
                    <div class="authors">CAIL</div>
                    <div class="title">Chinese AI and Law Challenge</div>
                    <div class="venue">Xiao et al., 2018</div>
                </div>
                <div class="citation-card">
                    <div class="authors">ECHR</div>
                    <div class="title">European Court of Human Rights cases</div>
                    <div class="venue">Chalkidis et al., 2019</div>
                </div>
            </div>
        </div>

        <div>
            <h3 class="font-semibold text-lg mb-4">Gap We Fill</h3>
            <div class="callout callout-warning">
                <p class="font-medium mb-2">No prior work integrates all three components:</p>
                <ul class="list-disc list-inside text-sm text-gray-600 space-y-1">
                    <li>Citation network structure</li>
                    <li>Full case text</li>
                    <li>LLM-based reasoning</li>
                </ul>
            </div>
            <p class="text-gray-600 mt-4 text-sm">
                Previous approaches either use citation networks for link prediction (without outcome prediction) or use text-only models (ignoring network structure). LegalGPT bridges this gap.
            </p>
        </div>
    </div>
</section>

<!-- Quick Links -->
<section class="grid md:grid-cols-3 gap-6">
    <a href="/methodology" class="card p-6 hover:bg-gray-50 transition group">
        <h3 class="font-bold text-lg mb-2 group-hover:text-blue-600">Methodology</h3>
        <p class="text-gray-600 text-sm">
            Technical details on GraphSAGE embeddings, hybrid retrieval, and QLoRA fine-tuning.
        </p>
    </a>
    <a href="/data" class="card p-6 hover:bg-gray-50 transition group">
        <h3 class="font-bold text-lg mb-2 group-hover:text-blue-600">Data</h3>
        <p class="text-gray-600 text-sm">
            Comprehensive analysis of SCDB dataset, citation graph, and data preprocessing.
        </p>
    </a>
    <a href="/results" class="card p-6 hover:bg-gray-50 transition group">
        <h3 class="font-bold text-lg mb-2 group-hover:text-blue-600">Results</h3>
        <p class="text-gray-600 text-sm">
            Full evaluation metrics, ablation studies, and comparison with baselines.
        </p>
    </a>
</section>
{% endblock %}
